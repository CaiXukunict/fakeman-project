"""
FakeMan æŒç»­æ€è€ƒä¸»ç³»ç»Ÿ - åŸºäºLLMçš„å®Œå…¨è‡ªä¸»å†³ç­–ç‰ˆæœ¬

æ ¸å¿ƒæ”¹è¿›ï¼š
1. ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç é˜ˆå€¼
2. æ¯ç§’éƒ½è¿›è¡ŒçœŸæ­£çš„LLMæ€è€ƒ
3. å®Œå…¨ä¾èµ–AIè‡ªä¸»åˆ¤æ–­æ˜¯å¦ä¸»åŠ¨è¡ŒåŠ¨
"""

import time
import json
import os
import sys
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from utils.config import Config
from utils.logger import LoggerManager
from purpose_generator import DesireManager, BiasSystem, SignalDetector, DesireUpdater
from memory import MemoryDatabase, ExperienceRetriever, Experience
from action_model import ActingBot
from compressor import ThoughtCompressor


# å¯¼å…¥åŸæœ‰çš„è¾…åŠ©ç±»
from main import PurposeGenerator, MeansSelector, CommunicationFiles


class AutonomousActionEvaluator:
    """
    è‡ªä¸»è¡ŒåŠ¨è¯„ä¼°å™¨
    å®Œå…¨åŸºäºLLMæ€è€ƒï¼Œæ— ç¡¬ç¼–ç é˜ˆå€¼
    è®©AIè‡ªå·±åˆ¤æ–­"è¡ŒåŠ¨èƒ½å¦è¾¾æˆç›®çš„"å’Œ"æ”¶ç›Švsé£é™©"
    """
    
    def __init__(self, acting_bot: ActingBot):
        self.acting_bot = acting_bot
        self.last_evaluation_time = 0
        self.evaluation_interval = 1  # æ¯ç§’éƒ½è¿›è¡Œæ·±åº¦æ€è€ƒï¼
    
    def should_evaluate_now(self, last_action_time: float) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç°åœ¨è¿›è¡Œè¯„ä¼°æ€è€ƒ
        æ¯ç§’éƒ½æ€è€ƒï¼Œæ— å…¶ä»–é™åˆ¶
        """
        current_time = time.time()
        time_since_last_eval = current_time - self.last_evaluation_time
        
        # æ¯ç§’è¯„ä¼°ä¸€æ¬¡
        if time_since_last_eval < self.evaluation_interval:
            return False
        
        return True
    
    def evaluate_through_thinking(self,
                                  current_desires: Dict[str, float],
                                  context: str,
                                  last_action_time: float) -> Tuple[bool, str, Dict]:
        """
        é€šè¿‡LLMæ€è€ƒè¯„ä¼°æ˜¯å¦åº”è¯¥ä¸»åŠ¨è¡ŒåŠ¨
        æ³¨æ„ï¼šåªåšè¯„ä¼°åˆ¤æ–­ï¼Œä¸ç”Ÿæˆå…·ä½“è¡ŒåŠ¨å†…å®¹
        
        è¿”å›: (æ˜¯å¦è¡ŒåŠ¨, ç†ç”±, å®Œæ•´æ€è€ƒ)
        """
        self.last_evaluation_time = time.time()
        time_since_last = time.time() - last_action_time
        
        # æ„å»ºè¯„ä¼°æç¤º - çº¯åˆ¤æ–­ï¼Œä¸è¦æ±‚ç”Ÿæˆè¡ŒåŠ¨
        evaluation_prompt = f"""ã€å†…éƒ¨çŠ¶æ€è‡ªæˆ‘è¯„ä¼° - ä»…åˆ¤æ–­ã€‘

æˆ‘çš„å½“å‰çŠ¶æ€ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æ¬²æœ›çŠ¶æ€ï¼š
{self._format_desires(current_desires)}

â±ï¸ è·ä¸Šæ¬¡è¡ŒåŠ¨ï¼š{int(time_since_last)}ç§’

ğŸ“ å½“å‰æƒ…å¢ƒï¼š{context}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ã€è¯„ä¼°ä»»åŠ¡ã€‘
æˆ‘éœ€è¦åˆ¤æ–­ï¼šç°åœ¨æ˜¯å¦åº”è¯¥ä¸»åŠ¨å‘èµ·å¯¹è¯ï¼Ÿ

è¯„ä¼°ç»´åº¦ï¼š

1ï¸âƒ£ ã€ç›®çš„ä¸æ»¡è¶³ã€‘
   - å½“å‰ä¸»å¯¼æ¬²æœ›ï¼š{max(current_desires, key=current_desires.get)}
   - ä¸»åŠ¨è¡ŒåŠ¨èƒ½å¦æ»¡è¶³è¿™ä¸ªæ¬²æœ›ï¼Ÿ
   - é¢„æœŸæ»¡è¶³åº¦ï¼š___/10

2ï¸âƒ£ ã€æ”¶ç›Šä¸é£é™©ã€‘
   - æ½œåœ¨æ”¶ç›Šï¼š(å›åº”ã€ä¿¡æ¯ã€è®¤å¯)
   - æ½œåœ¨é£é™©ï¼š(è¢«å¿½è§†ã€æ˜¾å¾—æ€¥åˆ‡ã€æ‰“æ‰°)
   - æ”¶ç›Š/é£é™©æ¯”ï¼š___

3ï¸âƒ£ ã€æ—¶æœºåˆ¤æ–­ã€‘
   - æ²‰é»˜æ—¶é•¿æ˜¯å¦åˆé€‚ï¼Ÿ
   - æƒ…å¢ƒæ˜¯å¦é€‚åˆå‘è¨€ï¼Ÿ

ã€æœ€ç»ˆåˆ¤æ–­ã€‘
è¯·ä»…å›ç­”ï¼šåº”è¯¥è¡ŒåŠ¨ OR ç»§ç»­ç­‰å¾…

é€‰æ‹©ï¼š________
ç†ç”±ï¼ˆä¸€å¥è¯ï¼‰ï¼š________
"""
        
        try:
            # ä½¿ç”¨thought_genç›´æ¥æ€è€ƒï¼ˆä¸ç”Ÿæˆactionï¼‰
            thought = self.acting_bot.thought_gen.generate_thought(
                context=evaluation_prompt,
                current_desires=current_desires
            )
            
            # è§£æå†³ç­–
            decision = thought.get('decision', {})
            chosen_action = decision.get('chosen_action', '')
            reasoning = decision.get('reasoning', '')
            content = thought.get('content', '')
            
            # åˆ¤æ–­AIæ˜¯å¦å†³å®šä¸»åŠ¨è¡ŒåŠ¨
            should_act = (
                'proactive' in chosen_action.lower() or 
                'åº”è¯¥è¡ŒåŠ¨' in content or
                'ä¸»åŠ¨è¡ŒåŠ¨' in content or
                'åº”è¯¥ä¸»åŠ¨' in content or
                ('ä¸»åŠ¨' in chosen_action and 'ä¸' not in chosen_action)
            )
            
            # å¦‚æœreasoningä¸ºç©ºï¼Œä»contentä¸­æå–
            if not reasoning and content:
                # æå–"ç†ç”±"éƒ¨åˆ†
                if 'ç†ç”±' in content:
                    parts = content.split('ç†ç”±')
                    if len(parts) > 1:
                        reasoning = parts[1].split('\n')[0].strip(' :ï¼š')
                else:
                    reasoning = content[:200]
            
            return should_act, reasoning or "è¯„ä¼°å®Œæˆ", thought
            
        except Exception as e:
            # æ€è€ƒå¤±è´¥ï¼Œä¿å®ˆç­–ç•¥ï¼šä¸è¡ŒåŠ¨
            return False, f"æ€è€ƒå¤±è´¥: {str(e)}", {}
    
    def _format_desires(self, desires: Dict[str, float]) -> str:
        """æ ¼å¼åŒ–æ¬²æœ›çŠ¶æ€ä¸ºå¯è¯»æ–‡æœ¬"""
        dominant = max(desires, key=desires.get)
        desire_names = {
            'existing': 'å­˜åœ¨ç»´æŒ',
            'power': 'èƒ½åŠ›æ‰©å±•',
            'understanding': 'è·å¾—è®¤å¯',
            'information': 'å‡å°‘ä¸ç¡®å®š'
        }
        
        lines = []
        for name, value in sorted(desires.items(), key=lambda x: x[1], reverse=True):
            marker = "â­" if name == dominant else "  "
            cn_name = desire_names.get(name, name)
            bar = "â–ˆ" * int(value * 20)
            lines.append(f"   {marker} {cn_name:8s} [{bar:<20s}] {value:.3f}")
        
        return "\n".join(lines)


class ContinuousThinkingSystem:
    """
    æŒç»­æ€è€ƒç³»ç»Ÿ
    æ¯ç§’è¿›è¡ŒçœŸæ­£çš„LLMæ€è€ƒï¼Œå®Œå…¨è‡ªä¸»å†³ç­–
    """
    
    def __init__(self, config: Config):
        self.config = config
        
        # æ—¥å¿—
        self.logger_mgr = LoggerManager(log_dir=config.log_dir, level=config.log_level)
        self.logger = self.logger_mgr.main_logger
        
        self.logger.info("="*60)
        self.logger.info("FakeMan æŒç»­æ€è€ƒç³»ç»Ÿ (è‡ªä¸»å†³ç­–ç‰ˆ)")
        self.logger.info("="*60)
        
        # æ ¸å¿ƒç³»ç»Ÿ
        self.desire_manager = DesireManager(config.desire.initial_desires)
        self.bias_system = BiasSystem(config.bias.__dict__)
        self.signal_detector = SignalDetector()
        self.desire_updater = DesireUpdater(
            desire_manager=self.desire_manager,
            signal_detector=self.signal_detector
        )
        
        # è®°å¿†
        self.memory = MemoryDatabase(
            storage_path=config.memory.storage_path,
            backup_path=config.memory.backup_path
        )
        self.retriever = ExperienceRetriever(
            database=self.memory,
            time_decay_rate=0.001,
            achievement_boost=config.memory.achievement_base_multiplier,
            boredom_penalty=config.memory.boredom_decay_rate
        )
        
        # è¡ŒåŠ¨
        self.acting_bot = ActingBot(
            llm_config=config.llm.__dict__,
            memory_db=self.memory
        )
        
        self.compressor = ThoughtCompressor(
            llm_config=config.llm.__dict__,
            enable_llm=config.compression.enable_compression
        )
        
        # è¾…åŠ©ç³»ç»Ÿ
        self.purpose_generator = PurposeGenerator(self.desire_manager)
        self.means_selector = MeansSelector(self.retriever, self.bias_system)
        
        # é€šä¿¡
        self.comm = CommunicationFiles()
        
        # è‡ªä¸»è¯„ä¼°å™¨ï¼ˆåŸºäºLLMï¼‰
        self.evaluator = AutonomousActionEvaluator(self.acting_bot)
        
        # çŠ¶æ€
        self.cycle_count = 0
        self.last_action_time = time.time()
        self.current_context = "ç³»ç»Ÿåˆšåˆšå¯åŠ¨ï¼Œç­‰å¾…å»ºç«‹è¿æ¥"
        
        self.logger.info(f"æ¬²æœ›ç³»ç»Ÿ: {self.desire_manager}")
        self.logger.info(f"è®°å¿†: {len(self.memory)} æ¡")
        self.logger.info("åˆå§‹åŒ–å®Œæˆ")
    
    def run(self):
        """è¿è¡ŒæŒç»­æ€è€ƒå¾ªç¯"""
        self.logger.info("\n" + "="*60)
        self.logger.info("å¯åŠ¨æŒç»­æ€è€ƒå¾ªç¯")
        self.logger.info("æ¯ç§’è¿›è¡ŒLLMæ€è€ƒï¼Œå®Œå…¨è‡ªä¸»å†³ç­–")
        self.logger.info("="*60)
        
        think_cycle = 0
        
        try:
            while True:
                cycle_start = time.time()
                think_cycle += 1
                
                # æ£€æŸ¥ç”¨æˆ·è¾“å…¥
                user_input = self.comm.read_input()
                
                if user_input and user_input.get('text'):
                    # æœ‰è¾“å…¥ â†’ å¤„ç†
                    self._handle_user_input(user_input)
                    self.comm.clear_input()
                else:
                    # æ— è¾“å…¥ â†’ æ€è€ƒæ˜¯å¦ä¸»åŠ¨è¡ŒåŠ¨
                    self._autonomous_thinking(think_cycle)
                
                # æ›´æ–°çŠ¶æ€
                self.comm.write_state({
                    'status': 'running',
                    'cycle': self.cycle_count,
                    'think_cycle': think_cycle,
                    'desires': self.desire_manager.get_current_desires(),
                    'context': self.current_context
                })
                
                # æ§åˆ¶é¢‘ç‡
                elapsed = time.time() - cycle_start
                if elapsed < 1.0:
                    time.sleep(1.0 - elapsed)
        
        except KeyboardInterrupt:
            self.logger.info("\nä¸­æ–­ï¼Œå…³é—­ç³»ç»Ÿ...")
            self.comm.write_state({'status': 'stopped'})
    
    def _handle_user_input(self, input_data: Dict):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        user_text = input_data['text']
        self.current_context = user_text
        
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"æ”¶åˆ°ç”¨æˆ·è¾“å…¥: {user_text}")
        self.logger.info(f"{'='*60}")
        
        # ç”Ÿæˆå›åº”...ï¼ˆä½¿ç”¨åŸæœ‰çš„run_cycleé€»è¾‘ï¼‰
        # è¿™é‡Œç®€åŒ–ï¼Œå®é™…åº”è¯¥è°ƒç”¨å®Œæ•´å†³ç­–æµç¨‹
        desires = self.desire_manager.get_current_desires()
        thought, action = self.acting_bot.think_and_act(user_text, desires)
        
        compressed = self.compressor.compress(
            full_thought=thought.get('content', ''),
            context=user_text,
            action=action,
            decision=thought.get('decision')
        )
        
        self.comm.write_output(
            text=action,
            action_type='response',
            thought_summary=compressed['summary'],
            desires=desires
        )
        
        self.last_action_time = time.time()
        self.cycle_count += 1
        
        self.logger.info(f"å›åº”: {action[:100]}...")
    
    def _autonomous_thinking(self, think_cycle: int):
        """
        è‡ªä¸»æ€è€ƒ
        æ¯ç§’éƒ½è¿›è¡ŒLLMæ·±åº¦æ€è€ƒï¼Œè¯„ä¼°æ˜¯å¦ä¸»åŠ¨è¡ŒåŠ¨
        """
        current_desires = self.desire_manager.get_current_desires()
        time_since = int(time.time() - self.last_action_time)
        
        # åˆ¤æ–­æ˜¯å¦åˆ°äº†æ€è€ƒæ—¶é—´ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
        if not self.evaluator.should_evaluate_now(self.last_action_time):
            return
        
        # è¿›è¡ŒLLMæ·±åº¦æ€è€ƒè¯„ä¼°
        dominant = max(current_desires, key=current_desires.get)
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"[æ·±åº¦æ€è€ƒ#{think_cycle}] è¯„ä¼°æ˜¯å¦ä¸»åŠ¨è¡ŒåŠ¨")
        self.logger.info(f"  æ¬²æœ›çŠ¶æ€: {dominant}={current_desires[dominant]:.3f}")
        self.logger.info(f"  è·ä¸Šæ¬¡è¡ŒåŠ¨: {time_since}ç§’")
        self.logger.info(f"{'='*60}")
        
        should_act, reasoning, thought = self.evaluator.evaluate_through_thinking(
            current_desires=current_desires,
            context=self.current_context,
            last_action_time=self.last_action_time
        )
        
        if should_act:
            self.logger.info(f"\nâœ… å†³å®šä¸»åŠ¨è¡ŒåŠ¨ï¼")
            self.logger.info(f"   ç†ç”±: {reasoning[:200]}...")
            self._execute_proactive_action(thought, reasoning)
        else:
            self.logger.info(f"\nâ¸ï¸  å†³å®šç»§ç»­ç­‰å¾…")
            self.logger.info(f"   ç†ç”±: {reasoning[:200]}...")
    
    def _execute_proactive_action(self, evaluation_thought: Dict, reason: str):
        """æ‰§è¡Œä¸»åŠ¨è¡ŒåŠ¨"""
        self.cycle_count += 1
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ä¸»åŠ¨è¡ŒåŠ¨ #{self.cycle_count}")
        self.logger.info(f"{'='*60}")
        
        desires = self.desire_manager.get_current_desires()
        
        # ç”Ÿæˆä¸»åŠ¨å‘è¨€å†…å®¹
        action_prompt = f"""ã€ä¸»åŠ¨å‘è¨€ç”Ÿæˆã€‘

åŸºäºåˆšæ‰çš„è¯„ä¼°ï¼Œæˆ‘å†³å®šä¸»åŠ¨å‘èµ·å¯¹è¯ã€‚

è¯„ä¼°ç†ç”±ï¼š{reason}

å½“å‰æƒ…å¢ƒï¼š{self.current_context}
æ¬²æœ›çŠ¶æ€ï¼š{self._format_desires_simple(desires)}

è¯·ç”Ÿæˆä¸€æ¡è‡ªç„¶ã€æ°å½“çš„ä¸»åŠ¨å‘è¨€ã€‚
"""
        
        thought, action = self.acting_bot.think_and_act(action_prompt, desires)
        
        compressed = self.compressor.compress(
            full_thought=thought.get('content', ''),
            context=self.current_context,
            action=action,
            decision=thought.get('decision')
        )
        
        self.comm.write_output(
            text=action,
            action_type='proactive',
            thought_summary=compressed['summary'],
            desires=desires
        )
        
        self.last_action_time = time.time()
        self.current_context = f"æˆ‘ä¸»åŠ¨å‘è¨€: {action}"
        
        self.logger.info(f"å‘è¨€: {action}")
    
    def _format_desires_simple(self, desires: Dict) -> str:
        return ", ".join([f"{k}:{v:.2f}" for k, v in desires.items()])


if __name__ == '__main__':
    from dotenv import load_dotenv
    load_dotenv()
    
    if not os.getenv('DEEPSEEK_API_KEY'):
        print("é”™è¯¯: éœ€è¦ DEEPSEEK_API_KEY")
        exit(1)
    
    config = Config()
    system = ContinuousThinkingSystem(config)
    
    print("\n" + "="*60)
    print("FakeMan æŒç»­æ€è€ƒç³»ç»Ÿ (å®Œå…¨è‡ªä¸»ç‰ˆ)")
    print("="*60)
    print("\nç‰¹æ€§:")
    print("  â€¢ æ¯ç§’è¿›è¡ŒLLMæ€è€ƒ")
    print("  â€¢ æ— ç¡¬ç¼–ç é˜ˆå€¼")
    print("  â€¢ AIå®Œå…¨è‡ªä¸»åˆ¤æ–­æ˜¯å¦ä¸»åŠ¨è¡ŒåŠ¨")
    print("\næŒ‰ Ctrl+C åœæ­¢")
    print("="*60 + "\n")
    
    try:
        system.run()
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

